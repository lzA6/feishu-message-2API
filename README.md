# 🚀 Feishu Message Scraper - 飞书消息抓取器 v2.2

[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![GitHub Repo](https://img.shields.io/badge/GitHub-lzA6/feishu--message--2API-blueviolet)](https://github.com/lzA6/feishu-message-2API)

> “我们并非在代码的海洋中寻求孤岛，而是在信息的洪流中构建桥梁。”

你好，未来的探索者！👋

欢迎来到 `feishu-message-2API` 项目。这不仅仅是一个工具，更是一次深入现代Web应用内部运作的冒险之旅。我们相信，通过亲手实践和理解技术的本质，每个人都能成为数字世界的建筑师，而不仅仅是使用者。

这个项目的诞生，源于一个简单而纯粹的需求：**当我们无法通过官方路径获取信息时，我们能否为自己开辟一条道路？** 答案是肯定的。本项目将带你一步步解开飞书Web端的神秘面纱，通过模拟客户端行为，让你能够以程序化的方式，稳定、可靠地获取指定群组的**历史消息**与**实时消息流**。

**我们的哲学很简单：**
*   **授人以渔 (Empowerment)**: 我们不仅提供一个能用的工具，更要教会你它是如何工作的。
*   **拥抱开源 (Open Source Spirit)**: 分享知识，协作改进，让好的想法走得更远。
*   **保持好奇 (Stay Curious)**: 技术的边界，就是我们探索的起点。

准备好了吗？让我们一起开始这次激动人心的逆向工程之旅吧！

---

### 🗺️ 一份蓝图：项目架构与数据流

为了确保这个工具能7x24小时稳定地为你工作，我们采用了业界成熟的**生产级微服务架构**。它就像一个分工明确、配合默契的特种小队。

**架构图:**
```
+----------------------+      +--------------------------------+      +------------------------+
|      你的应用/脚本      | ---> | Nginx (反向代理/哨兵) @ 8008   | ---> | FastAPI 应用 (大脑)      |
| (e.g., curl, Python) |      |        (Docker 容器 1)         |      | (Docker 容器 2)        |
+----------------------+      +--------------------------------+      +------------------------+
                                                                           |
                                                                           | (伪装成真实用户)
                                                                           v
                                                                 +------------------------+
                                                                 |      飞书 API 服务器     |
                                                                 +------------------------+
```

**小队成员介绍:**

*   🧠 **FastAPI 应用 (Python)**: 项目的**大脑和执行者**。它负责所有核心任务：
    1.  接收你的指令（比如“去抓取这个群的消息”）。
    2.  穿上“伪装服”（也就是你的 `Cookie`），假扮成一个真实的、已登录的你。
    3.  用飞书的“内部语言” **Protobuf** (一种高效的二进制数据格式) 发送请求。
    4.  接收服务器返回的加密情报（二进制数据流），并用我们逆向工程得到的“密码本” (`.proto` 文件) 将其**解码**成人类可读的JSON格式。
    5.  通过HTTP（一次性获取）或WebSocket（实时推送）将整理好的情报交给你。

*   💂 **Nginx (哨兵与交通指挥)**: 项目的**门户和守护者**。
    *   **反向代理 (Reverse Proxy)**: 它是唯一对外暴露的接口。所有外部请求都先经过它，再由它安全地转发给内部的FastAPI大脑。这就像一个门卫，保护了内部核心成员不直接暴露在外。
    *   **负载均衡 (Load Balancing)**: 虽然现在只有一个“大脑”，但未来如果你需要处理海量请求，可以启动多个FastAPI实例，Nginx会自动将任务分发给最空闲的那个，保证系统不会过载。

*   📦 **Docker & Docker Compose (标准化营房)**: 我们的**后勤保障系统**。
    *   **Docker**: 将Nginx和FastAPI以及它们所有的依赖（比如Python环境、各种库）分别打包成一个标准化的“集装箱”（容器）。
    *   **Docker Compose**: 负责一键搭建整个营地。它会根据 `docker-compose.yml` 这份“搭建图纸”，自动构建并启动所有“集装箱”，并铺设好它们之间的“通信线路”。这保证了无论是在你的Windows、Mac还是Linux服务器上，整个系统都能以完全相同的方式、一键运行起来。

---

### 🔬 一份深度报告：核心技术点揭秘

#### **1. 身份模拟的核心：Cookie 认证**

*   **专业术语**: **会话管理 (Session Management)**
*   **大白话**: 当你在浏览器上登录飞书后，服务器会给你一个独一无二的“电子通行证”，这就是 `Cookie`。在之后的一段时间里，你每次向飞书发送请求，浏览器都会自动带上这个通行证，服务器一看就知道“哦，是自己人”。我们的项目就是通过在 `.env` 文件里配置这个 `Cookie`，让我们的Python脚本也能带上这个通行证，从而成功“混入”内部。
*   **优缺点**:
    *   👍 **优点**: 实现简单，无需处理复杂的登录加密流程。
    *   👎 **缺点**: Cookie会过期！你需要定期手动更新它。这是所有此类方案的“阿喀琉斯之踵”。

#### **2. 飞书的“悄悄话”：Protocol Buffers (Protobuf)**

*   **专业术语**: **二进制序列化协议 (Binary Serialization Protocol)**
*   **大白话**: 想象一下JSON是一封用明文写的信，谁都能读懂，但有点啰嗦。Protobuf就像是把这封信转换成了高效的二进制“电报码”。它传输速度快、占用空间小，但如果没有对应的“密码本”(`.proto`文件)，你收到就是一堆乱码。
*   **我们的实现**: 我们通过分析网络行为，**逆向推测**出了这个密码本的结构，并创建了 `feishu_im.proto` 文件。在Docker构建阶段，我们会用 `protoc` 工具（一个翻译器）把这个密码本编译成Python能理解的 `feishu_im_pb2.py` 模块。`feishu_provider.py` 在收到服务器的二进制数据后，就调用这个模块来完成解码。
*   **技术点**:
    *   `feishu_im.proto`: 定义了数据结构，比如一个 `Message` 包含 `sender`、`content` 等。
    *   `ParseFromString()`: 这是Protobuf模块提供的核心解码函数，将二进制字节流转换成Python对象。
    *   `SerializeToString()`: 这是编码函数，用于将我们构建的请求对象转换成二进制数据发送给服务器。

#### **3. 实时消息的魔法：长轮询 (Long Polling)**

*   **专业术语**: **服务器推送技术的一种模拟实现**
*   **大白话**: 传统的“你问我答”（HTTP请求）模式不适合实时聊天。你总不能每秒都问一次“有新消息吗？”，这样太浪费资源了。长轮询是一种聪明的技巧：
    1.  我们的程序向服务器发送一个请求：“有新消息吗？如果没有，先别急着回答我，等有了再说。”
    2.  服务器收到后，如果没有新消息，就“憋着”这个请求不回应，直到有新消息进来，或者等了很久（比如60秒）实在没等到。
    3.  一旦有新消息，服务器立刻把消息作为响应返回。我们的程序收到后，马上处理，然后立刻再发送一个新的“憋着”的请求。
*   **我们的实现**: 在 `feishu_provider.py` 的 `stream_latest_messages` 函数中，我们设置了一个很长的 `timeout=60`。如果60秒内收到响应，就处理数据；如果60秒后依然没收到（触发 `requests.exceptions.Timeout`），我们就知道这期间没有新消息，然后心平气和地进入下一次循环，继续监听。

---

### 🧑‍🏫 一份保姆级教程：从零到一，三步启动

#### **第 1 步：环境准备**

确保你的电脑或服务器上安装了 **Docker** 和 **Docker Compose**。
*   **Windows/Mac用户**: 直接安装 [Docker Desktop](https://www.docker.com/get-started) 即可。
*   **Linux用户**: 请参考官方文档安装 `docker` 和 `docker-compose`。

#### **第 2 步：获取项目并配置**

1.  **克隆仓库**: 打开终端，运行以下命令将项目下载到本地。
    ```bash
    git clone https://github.com/lzA6/feishu-message-2API.git
    cd feishu-message-2API
    ```
2.  **创建并编辑配置文件**:
    ```bash
    # 复制模板文件
    cp .env.example .env
    ```
    然后，用你喜欢的文本编辑器打开 `.env` 文件。

3.  **【❗❗❗ 核心中的核心：填入情报 ❗❗❗】**
    *   **获取 `FEISHU_COOKIE`**:
        *   在Chrome浏览器登录飞书网页版。
        *   按 `F12` 打开开发者工具，切换到“网络(Network)”面板。
        *   随便点击一个请求（比如 `gateway` 或 `list`），在右侧的“标头(Headers)” -> “请求标头(Request Headers)”中，找到 `cookie:` 这一行，**复制它的全部值**。
        *   将这串长长的值粘贴到 `.env` 文件的 `FEISHU_COOKIE="..."` 的引号中。
    *   **获取 `COMMAND_ID`**:
        *   按照 `README.md` 上一章节的“抓包指南”，通过**向上滚动加载历史**和**接收新消息**这两个动作，分别找到对应的 `gateway` 请求。
        *   从这两个请求的请求头中，分别找到 `x-command` 的值。
        *   将它们填入 `.env` 文件的 `COMMAND_ID_HISTORY="..."` 和 `COMMAND_ID_STREAM="..."` 中。

#### **第 3 步：🚀 一键启动！**

在项目根目录下，运行：
```bash
docker-compose up --build
```
等待Docker完成它的魔法。当看到日志开始滚动并显示 `Uvicorn running on http://0.0.0.0:8000` 时，恭喜你，你的个人飞书API已经成功部署！

---

### ✨ 懒人一键部署教程 (Hugging Face Spaces)

如果你不想在本地配置环境，可以尝试使用 Hugging Face Spaces 进行云端部署。

[![Deploy to Hugging Face Spaces](https://hf.co/datasets/huggingface/badges/raw/main/deploy-to-spaces-lg.svg)](https://huggingface.co/new-space?template=docker&stub=lzA6/feishu-message-2API)

**点击上面的按钮，你会被引导到一个新的页面：**

1.  **Space name**: 给你的项目起个名字。
2.  **Secrets**: 这是最关键的一步！
    *   点击 **"New secret"**。
    *   **Name**: 输入 `FEISHU_COOKIE`
    *   **Value**: 粘贴你的Cookie值。
    *   再次点击 **"New secret"**。
    *   **Name**: 输入 `COMMAND_ID_HISTORY`
    *   **Value**: 粘贴你获取的历史消息 `x-command` 值。
    *   再次点击 **"New secret"**。
    *   **Name**: 输入 `COMMAND_ID_STREAM`
    *   **Value**: 粘贴你获取的实时消息 `x-command` 值。
3.  点击 **"Create Space"**。Hugging Face 会自动为你构建并部署应用。等待几分钟，当看到状态变为 `Running` 时，你就可以通过它提供的公开URL来访问你的API了！

---

### 🎯 项目现状与未来展望

#### **现阶段我们完成了什么？**

*   ✅ **完整的生产级架构**: 基于Docker、Nginx和FastAPI，稳定可靠。
*   ✅ **历史消息获取**: 实现了可翻页的历史消息拉取功能。
*   ✅ **实时消息流**: 通过WebSocket和长轮询，实现了新消息的实时推送。
*   ✅ **断点续传**: 即使服务重启，也能从上次中断的地方继续接收新消息，不重不漏。
*   ✅ **核心信息解析**: 能够解析出消息ID、发送者ID、姓名、头像和文本内容。
*   ✅ **配置外部化**: 所有敏感和易变信息都已移至 `.env` 文件，便于维护。

#### **它能用在什么场景？**

*   **个人消息存档**: 将重要的群聊信息自动备份到你自己的数据库或文件中。
*   **信息聚合与摘要**: 构建一个Dashboard，实时展示多个群的关键信息，并进行AI摘要。
*   **机会发现**: 监控特定关键词（例如“招聘”、“合作”、“需求”），一旦出现就立即通过邮件或其他方式通知你。
*   **与其他服务联动**: 将群消息作为触发器，通过IFTTT或Zapier等工具，联动其他应用（例如，当群里提到“bug”时，自动在Jira里创建一个任务）。

#### **有什么缺点和限制？**

1.  **Cookie 依赖**: 这是最大的软肋。Cookie会过期，需要你定期手动更新。
2.  **API 稳定性**: 我们依赖的是非官方内部API，飞书随时可能更改它，导致项目失效。
3.  **Protobuf 定义局限**: 目前的 `.proto` 文件只能解析文本消息和基础的用户信息。对于图片、文件、卡片、表情等复杂消息，它会直接忽略内容。

#### **未来可以如何扩展？ 🚀**

这个项目只是一个起点，未来有无限可能！

*   **🤖 引入 AI 能力**:
    *   **自动摘要**: 对每个小时或每天的群聊内容进行AI摘要，生成简报。
    *   **情感分析**: 分析群聊的情绪走向，是积极还是消极。
    *   **智能问答**: 将群聊记录作为知识库，训练一个可以回答“群里之前关于XX项目是怎么讨论的？”的AI助手。

*   **🧩 完善 Protobuf 解码**:
    *   通过更深入的抓包，逆向出图片、文件、引用、卡片等复杂消息的 `.proto` 结构，让我们的API能解析一切。

*   **💾 增加数据持久化**:
    *   将获取到的消息自动存入SQLite、PostgreSQL或MongoDB等数据库中，方便长期存储和检索。

*   **🔐 自动化 Cookie 续期**:
    *   这是一个高阶挑战。通过模拟完整的登录流程（可能需要处理验证码），实现Cookie的自动刷新，彻底摆脱手动更新的烦恼。

---

### ⚖️ 开源协议

本项目采用 **Apache License 2.0**。

我们鼓励一切形式的贡献，无论是提交代码、修复Bug，还是完善这份文档。让我们一起，在开源的世界里，创造更多有趣且有价值的东西！

---

**感谢阅读，现在，去创造吧！** ✨
